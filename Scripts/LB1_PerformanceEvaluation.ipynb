{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Performance evaluation of the HMMs obtained**"
      ],
      "metadata": {
        "id": "KeU2ytK4nJJ7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxAsluuCaHk5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report, matthews_corrcoef, auc\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "QE8VBKAeedig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "fjdLb5wEoyLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function that takes as input an array containing E-values and a threshold and produces predictions based on them\n",
        "def get_preds(x,th):\n",
        "  l_pred =[]\n",
        "  for value in x:\n",
        "    if value<=th:\n",
        "      l_pred.append(1)\n",
        "    else:\n",
        "      l_pred.append(0)\n",
        "  pred = np.array(l_pred)\n",
        "  return pred\n",
        "\n",
        "# function that takes as input the confusion matrix obtained with the method confusion_matrix() from sklearn.metrics and print it\n",
        "def print_cm(cm,th):\n",
        "  TN, FP, FN, TP = cm.ravel()\n",
        "  plt.figure(figsize=(3, 2))\n",
        "  sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', cbar=False, annot_kws={\"size\": 7},\n",
        "              xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
        "  plt.xlabel('Predicted')\n",
        "  plt.ylabel('Real')\n",
        "  title = 'Confusion matrix with th='+str(th)\n",
        "  plt.title(title+'\\nTP={}, TN={}, FP={}, FN={}'.format(TP, TN, FP, FN))\n",
        "  plt.show()\n",
        "  return TN, FP, FN, TP\n",
        "\n",
        "# funtcion that takes as input the TPR and FPR lists and print the ROC curve\n",
        "def print_ROC_curve(FPR_list, TPR_list):\n",
        "  plt.plot(FPR_list, TPR_list, linestyle='-', color='r', linewidth=3)\n",
        "  plt.plot([0, 1], [0, 1], linestyle='--', color='red')\n",
        "  max_TPR = max(TPR_list)\n",
        "  max_TPR_index = TPR_list.index(max_TPR)\n",
        "  plt.axhline(y=max_TPR, color='b', linestyle='--', label=f'Maximum TPR: {max_TPR:.2f}')\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title('ROC Curve')\n",
        "  plt.xlim([0, 1])\n",
        "  plt.ylim([0, 1.05])\n",
        "  plt.grid(True)\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  roc_auc = auc(FPR_list, TPR_list)\n",
        "  print('AUC =', roc_auc)"
      ],
      "metadata": {
        "id": "Az0Ea4CscDoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 1.   Optimization\n",
        "\n"
      ],
      "metadata": {
        "id": "rHPbbTh7p2ZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set loading**"
      ],
      "metadata": {
        "id": "8cajRYIyrIEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subset1 = files.upload()\n",
        "# upload opt1_seq.txt for the multiple sequence alignment model\n",
        "# upload opt1_str.txt for the multiple structure alignment model"
      ],
      "metadata": {
        "id": "xFqSyxOop3ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subset2 = files.upload()\n",
        "# upload opt2_seq.txt for the multiple sequence alignment model\n",
        "# upload opt2_str.txt for the multiple structure alignment model"
      ],
      "metadata": {
        "id": "FOqYLiFwrCKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = files.upload()\n",
        "# upload test_seq.txt for the multiple sequence alignment model\n",
        "# upload test_str.txt for the multiple structure alignment model"
      ],
      "metadata": {
        "id": "EgYthJxhrVXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### 1.1.   Subset1 as optimization set and subset2 as valdation set\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b7HQI09aqD1L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataframe creation**"
      ],
      "metadata": {
        "id": "2g22i7AAqn3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for file_name, content in subset1.items():\n",
        "  opt1_df = pd.read_csv(file_name, sep='\\t', header=None, names=['ID', 'E-value', 'Label'])"
      ],
      "metadata": {
        "id": "j4YfWPm2p4vF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt1_df.head()"
      ],
      "metadata": {
        "id": "24aqsBvbr6Bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt1_df.shape"
      ],
      "metadata": {
        "id": "rdWPLPItsVF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file_name, content in subset2.items():\n",
        "  val1_df = pd.read_csv(file_name, sep='\\t', header=None, names=['ID', 'E-value', 'Label'])"
      ],
      "metadata": {
        "id": "XJ9VHFokr8TB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val1_df.head()"
      ],
      "metadata": {
        "id": "UX-QMgTAr85Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val1_df.shape"
      ],
      "metadata": {
        "id": "BFN7p2DEsW4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creation of two optimization arrays containing the E-values and the labels**"
      ],
      "metadata": {
        "id": "wStpReGvp5GA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_opt1= opt1_df[\"E-value\"].to_numpy()\n",
        "y_opt1= opt1_df[\"Label\"].to_numpy()"
      ],
      "metadata": {
        "id": "YfwreOrtsooj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_opt1"
      ],
      "metadata": {
        "id": "0wjqGzZSs56y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_opt1"
      ],
      "metadata": {
        "id": "x8cFcZe0s-Ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creation of two validation arrays containing the E-values and the labels**"
      ],
      "metadata": {
        "id": "-I0tC3qjtNn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_val1= val1_df[\"E-value\"].to_numpy()\n",
        "y_val1= val1_df[\"Label\"].to_numpy()"
      ],
      "metadata": {
        "id": "dZadAZUHtPqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val1"
      ],
      "metadata": {
        "id": "cHfwg-pMtV98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_val1"
      ],
      "metadata": {
        "id": "73OGYQCttVv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Obtaining predictions and classification report using various E-value tresholds**"
      ],
      "metadata": {
        "id": "yu9UMSqWtgef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols = ['Threshold','Accuracy','Pos_f1_score','Neg_f1_score','MCC','TPR','FPR']\n",
        "res_opt1 = pd.DataFrame(columns=cols)\n",
        "# creation of a dataframe that will be used to visualize better the results"
      ],
      "metadata": {
        "id": "rcXagmUrtgEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt1_TPR_list = []\n",
        "opt1_FPR_list = []\n",
        "\n",
        "for th in [0.0001, 0.00001, 0.000001, 0.0000001, 0.00000001, 0.000000001, 0.0000000001, 0.00000000001]:\n",
        "  y_pred1 = get_preds(X_opt1, th)\n",
        "  cm = confusion_matrix(y_opt1, y_pred1)\n",
        "  TN, FP, FN, TP = print_cm(cm, th)\n",
        "  report = classification_report(y_opt1, y_pred1, output_dict=True)\n",
        "  ac, pos_f1, neg_f1, mcc = report['accuracy'], report['1']['f1-score'], report['0']['f1-score'], matthews_corrcoef(y_opt1, y_pred1)\n",
        "  print('THRESHOLD=%s\\nAccuracy=%s\\nPositive F1=%s\\nNegative F1=%s\\nMCC=%s\\n'%(th,ac,pos_f1,neg_f1,mcc))\n",
        "  opt1_TPR_current = TP / (TP + FN)\n",
        "  opt1_FPR_current = FP / (FP + TN)\n",
        "  opt1_TPR_list.append(opt1_TPR_current)\n",
        "  opt1_FPR_list.append(opt1_FPR_current)\n",
        "  new_res = [th, ac, pos_f1, neg_f1, mcc, opt1_TPR_current, opt1_FPR_current]\n",
        "  res_opt1.loc[len(res_opt1)] = new_res\n"
      ],
      "metadata": {
        "id": "lOmA-HOxgumM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ROC curve**"
      ],
      "metadata": {
        "id": "x4O1HCeUuX5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_ROC_curve(opt1_FPR_list, opt1_TPR_list)\n",
        "print(res_opt1)"
      ],
      "metadata": {
        "id": "8wn2bQ_kuami"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Validation of the best threshold**"
      ],
      "metadata": {
        "id": "PlRZ6T2VupFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "th = # INSERT BEST THRESHOLD SELECTED\n",
        "# best threshold selected for the multiple sequence alignment model is 0.000000001\n",
        "# best threshold selected for the multiple structure alignment model is 0.00000001"
      ],
      "metadata": {
        "id": "h4jSiH-gu9zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred1 = get_preds(X_val1, th)\n",
        "cm = confusion_matrix(y_val1, y_pred1)\n",
        "TN, FP, FN, TP = print_cm(cm,th)\n",
        "report = classification_report(y_val1, y_pred1, output_dict=True)\n",
        "ac, pos_f1, neg_f1, mcc = report['accuracy'], report['1']['f1-score'], report['0']['f1-score'], matthews_corrcoef(y_val1, y_pred1)\n",
        "print('THRESHOLD=%s\\nAccuracy=%s\\nPositive F1=%s\\nNegative F1=%s\\nMCC=%s\\n'%(th,ac,pos_f1,neg_f1,mcc))"
      ],
      "metadata": {
        "id": "K3a8hkHmubbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### 1.1.   Subset2 as optimization set and subset1 as valdation set\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S7Dzfg5GxA7f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataframe creation**"
      ],
      "metadata": {
        "id": "lKso-6SAxA7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for file_name, content in subset2.items():\n",
        "  opt2_df = pd.read_csv(file_name, sep='\\t', header=None, names=['ID', 'E-value', 'Label'])"
      ],
      "metadata": {
        "id": "_rDOfw4xxA7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt2_df.head()"
      ],
      "metadata": {
        "id": "XJRWhuZ-xA7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt2_df.shape"
      ],
      "metadata": {
        "id": "-uuDn3sKxA7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file_name, content in subset1.items():\n",
        "  val2_df = pd.read_csv(file_name, sep='\\t', header=None, names=['ID', 'E-value', 'Label'])"
      ],
      "metadata": {
        "id": "zvDnhYVtxA7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val2_df.head()"
      ],
      "metadata": {
        "id": "imdUVNZqxA7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val2_df.shape"
      ],
      "metadata": {
        "id": "vljFyjPNxA7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creation of two optimization arrays containing the E-values and the labels**"
      ],
      "metadata": {
        "id": "Kj5KtBwexA7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_opt2 = opt2_df[\"E-value\"].to_numpy()\n",
        "y_opt2 = opt2_df[\"Label\"].to_numpy()"
      ],
      "metadata": {
        "id": "tpcCQbyAxA7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_opt2"
      ],
      "metadata": {
        "id": "gfQ6QbOhxA7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_opt2"
      ],
      "metadata": {
        "id": "FnfFOQrtxA7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creation of two validation arrays containing the E-values and the labels**"
      ],
      "metadata": {
        "id": "pH9tUe7GxA7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_val2 = val2_df[\"E-value\"].to_numpy()\n",
        "y_val2 = val2_df[\"Label\"].to_numpy()"
      ],
      "metadata": {
        "id": "Dt1tLEVhxA7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val2"
      ],
      "metadata": {
        "id": "r89aK3XAxA7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_val2"
      ],
      "metadata": {
        "id": "V1UQlI_JxA7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Obtaining predictions and classification report using various E-value tresholds**"
      ],
      "metadata": {
        "id": "5priTjczxA7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols = ['Threshold','Accuracy','Pos_f1_score','Neg_f1_score','MCC','TPR','FPR']\n",
        "res_opt2 = pd.DataFrame(columns=cols)\n",
        "# creation of a dataframe that will be used to visualize better the results"
      ],
      "metadata": {
        "id": "DprB6yX3xA7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt2_TPR_list = []\n",
        "opt2_FPR_list = []\n",
        "\n",
        "for th in [0.0001, 0.00001, 0.000001, 0.0000001, 0.00000001, 0.000000001, 0.0000000001, 0.00000000001]:\n",
        "  y_pred2 = get_preds(X_opt2, th)\n",
        "  cm = confusion_matrix(y_opt2, y_pred2)\n",
        "  TN, FP, FN, TP = print_cm(cm, th)\n",
        "  report = classification_report(y_opt2, y_pred2, output_dict=True)\n",
        "  ac, pos_f1, neg_f1, mcc = report['accuracy'], report['1']['f1-score'], report['0']['f1-score'], matthews_corrcoef(y_opt2, y_pred2)\n",
        "  print('THRESHOLD=%s\\nAccuracy=%s\\nPositive F1=%s\\nNegative F1=%s\\nMCC=%s\\n'%(th,ac,pos_f1,neg_f1,mcc))\n",
        "  opt2_TPR_current = TP / (TP + FN)\n",
        "  opt2_FPR_current = FP / (FP + TN)\n",
        "  opt2_TPR_list.append(opt2_TPR_current)\n",
        "  opt2_FPR_list.append(opt2_FPR_current)\n",
        "  new_res = [th, ac, pos_f1, neg_f1, mcc, opt2_TPR_current, opt2_FPR_current]\n",
        "  res_opt2.loc[len(res_opt2)] = new_res\n"
      ],
      "metadata": {
        "id": "2ywCYNIJxA70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ROC curve**"
      ],
      "metadata": {
        "id": "bB5s7dMTxA71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_ROC_curve(opt2_FPR_list, opt2_TPR_list)\n",
        "print(res_opt2)"
      ],
      "metadata": {
        "id": "F3UhWrKaxA72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Validation of the best threshold**"
      ],
      "metadata": {
        "id": "hvT7oVTdxA73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "th2 = # INSERT BEST THRESHOLD SELECTED\n",
        "# best threshold selected for the multiple sequence alignment model is 0.000001\n",
        "# best threshold selected for the multiple structure alignment model is 0.000001"
      ],
      "metadata": {
        "id": "nb3nVlMUxA74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred2 = get_preds(X_val2, th2)\n",
        "cm = confusion_matrix(y_val2, y_pred2)\n",
        "TN, FP, FN, TP = print_cm(cm, th2)\n",
        "report = classification_report(y_val2, y_pred2, output_dict=True)\n",
        "ac, pos_f1, neg_f1, mcc = report['accuracy'], report['1']['f1-score'], report['0']['f1-score'], matthews_corrcoef(y_val2, y_pred2)\n",
        "print('THRESHOLD=%s\\nAccuracy=%s\\nPositive F1=%s\\nNegative F1=%s\\nMCC=%s\\n'%(th2,ac,pos_f1,neg_f1,mcc))"
      ],
      "metadata": {
        "id": "WJ_NFfBYxA75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 2.   Final test\n",
        "\n"
      ],
      "metadata": {
        "id": "zHJSI0xnyrbm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataframe creation**"
      ],
      "metadata": {
        "id": "zra8w4QLy4WM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for file_name, content in test_set.items():\n",
        "  test_df = pd.read_csv(file_name, sep='\\t', header=None, names=['ID_proteina', 'E-value', 'Label'])"
      ],
      "metadata": {
        "id": "msERgw7exA77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "id": "gI3Tfdzkzj2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.shape"
      ],
      "metadata": {
        "id": "N9Ntw6Qszltv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creation of two arrays containing the E-values and the labels**"
      ],
      "metadata": {
        "id": "GwG9YBIgzA1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test_df['E-value'].to_numpy()\n",
        "y_test = test_df['Label'].to_numpy()"
      ],
      "metadata": {
        "id": "h9p2t5PpzAS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0P4T9z4ezxSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "th = # insert the average of the best thresholds\n",
        "# threshold selected for the multiple sequence alignment model is 0.00000003162\n",
        "# threshold selected for the multiple structure alignment model is 0.0000001"
      ],
      "metadata": {
        "id": "IeD1PlV2zys7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred3 = get_preds(X_test, th)\n",
        "cm = confusion_matrix(y_test, y_pred3)\n",
        "TN, FP, FN, TP = print_cm(cm, th)\n",
        "report = classification_report(y_test, y_pred3, output_dict=True)\n",
        "ac, pos_f1, neg_f1, mcc = report['accuracy'], report['1']['f1-score'], report['0']['f1-score'], matthews_corrcoef(y_test, y_pred3)\n",
        "print('THRESHOLD=%s\\nAccuracy=%s\\nPositive F1=%s\\nNegative F1=%s\\nMCC=%s\\n'%(th,ac,pos_f1,neg_f1,mcc))"
      ],
      "metadata": {
        "id": "GDP8AJrJzxyx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}